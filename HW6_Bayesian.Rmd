---
title: "Bayesian"
author: "Nashrah Ahmed"
date: "April 25, 2018"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
knitr::opts_chunk$set(cache=TRUE)
if (!require("brms")) install.packages("brms")
if (!require("sampleSelection")) install.packages("sampleSelection")
library(brms)
library(arm)
library(rstan)
library(rstanarm)
rstan_options(auto_write = TRUE)
set.seed(12345)
```

#Question 1
```{r}
expose_stan_functions("trafficstops.stan")
```

```{stan output.var = "trafficstops", eval = FALSE}
functions {
  real beta_ccdf(real x, real a, real b) {
    return beta_cdf(1 - x, b, a);
  }
  
  // E[X | X > x] for X target += beta(a,b)
  real beta_conditional_mean(real x, real a, real b) {
    return beta_ccdf(x, a+1, b) / beta_ccdf(x, a, b) * a / (a+b);
  }
}

data {
  int<lower=1> N; // number of observations
  int<lower=1> R; // number of suspect races
  int<lower=1> D; // number of counties
  
  int<lower=1,upper=R> r[N]; // race of suspect
  int<lower=1,upper=D> d[N]; // county where stop occurred
  
  int<lower=1> n[N]; // # of stops
    int<lower=0> s[N]; // # of searches
    int<lower=0> h[N]; // # of successful searches (hits)
}

parameters {	
  // hyperparameters
  vector<lower=0>[R] sigma_t;
  real mu_phi_d;
  real<lower=0> sigma_phi_d;
  real mu_lambda_d;
  real<lower=0> sigma_lambda_d;
  
  // search thresholds
  vector[R] t_r;
  vector[N] t_i_raw;
  
  // parameters for signal distribution
  vector[R] phi_r;
  vector[D-1] phi_d_raw;
  
  vector[R] lambda_r; 
  vector[D-1] lambda_d_raw;
}

transformed parameters {
  vector[D] phi_d;
  vector[D] lambda_d;
  vector[N] phi;
  vector[N] lambda;
  vector<lower=0, upper=1>[N] search_rate;
  vector<lower=0, upper=1>[N] hit_rate;
  vector<lower=0, upper=1>[N] t_i;
  
  phi_d    = mu_phi_d + phi_d_raw * sigma_phi_d;
  lambda_d = mu_lambda_d + lambda_d_raw * sigma_lambda_d;
  
  for (i in 1:N) {	
    real a;
    real b;
    
    // implies t_i[i] target += logit-normal_lpdf(t_r[r[i]], sigma_t[r[i]])
    t_i[i] = inv_logit(t_r[r[i]] + t_i_raw[i] * sigma_t[r[i]]);
    
    // signal distribution parameters	
    phi[i]    = inv_logit(phi_r[r[i]] + phi_d[d[i]]);
    lambda[i] = exp(lambda_r[r[i]] + lambda_d[d[i]]);
    
    // transformed signal distribution parameters
    a = lambda[i] * phi[i];
    b = lambda[i] * (1 - phi[i]);
    
    // implied search and hit rates
    search_rate[i] = beta_ccdf(t_i[i], a, b);
    hit_rate[i]    = beta_conditional_mean(t_i[i], a, b);
  }
}

model {  
  // Draw threshold hyperparameters
  target += normal_lpdf(sigma_t | 0, 2);
  target += normal_lpdf(t_r | 0, 2);
  
  // Department hyperparameters for department parameters
  target += normal_lpdf(mu_phi_d | 0, 2);
  target += normal_lpdf(sigma_phi_d | 0, 2);
  target += normal_lpdf(mu_lambda_d | 0, 2);
  target += normal_lpdf(sigma_lambda_d | 0, 2);
  
  // Draw race parameters
  target += normal_lpdf(phi_r | 0, 2);
  target += normal_lpdf(lambda_r | 0, 2);
  
  // Draw department parameters (for un-pinned departments)
  target += normal_lpdf(phi_d_raw | 0, 1);     // implies phi_d target += N(mu_phi_d, sigma_phi_d)
  target += normal_lpdf(lambda_d_raw | 0, 1);  // implies lambda_d target += N(mu_lambda_d, sigma_lambda_d)
  
  // Draw race and department specific thresholds
  target += normal_lpdf(t_i_raw | 0, 1);        // implies t_i target += logit-normal_lpdf(t_r, sigma_t)
  
  // Draw search and hit observations
  target += binomial_lpmf(s | n, search_rate);
  target += binomial_lpmf(h | s, hit_rate);
}



generated quantities {
  // Stop-weighted per-race parameters
  vector[R] thresholds;
  
  {
    vector[R] counts;
    vector[D] dep_stops;
    
    thresholds = rep_vector(0, R);
    counts     = rep_vector(0, R);
    dep_stops  = rep_vector(0, D);
    
    
    // calculate total stops per department
    for (i in 1:N) {
      dep_stops[d[i]] = dep_stops[d[i]] + n[i];
    }
    
    for (i in 1:N) {
      thresholds[r[i]] = thresholds[r[i]] + t_i[i]*dep_stops[d[i]];
      counts[r[i]]     = counts[r[i]] + dep_stops[d[i]];
    }
    thresholds = thresholds ./ counts;
  }
}

```
#Continuation of Question 1
```{r, eval=FALSE}
setwd("/Users/Nashrah/Desktop/Columbia_QMSS/Spring 2018 Courses/Bayesian Stats")
df = read.csv("north_carolina.csv")
#data not sampling
output <- stan("trafficstops.stan", data = "north_carolina.csv")
#reformat to comply with stan, however still not sampling
obs <- df %>% 
  group_by(police_department, race) %>%
  summarise(num_stops = n(),
      num_searches = sum(search_conducted),
      num_hits = sum(contraband_found, na.rm = TRUE),
      search_rate = num_searches/num_stops,
      hit_rate = num_hits/num_searches) %>%
  filter(num_searches != 0) %>%
  as.data.frame()
    
sorted_departments <- obs %>% 
  group_by(police_department) %>% 
  summarize(num_stops = sum(num_stops)) %>% 
  arrange(desc(num_stops)) 
  
obs <- obs %>%
  mutate(race = factor(race, levels = unique(obs$race)),
         police_department = factor(police_department, levels = unique(sorted_departments$police_department))) %>%
  arrange(desc(num_stops)) %>%
  as.data.frame()
    
stan_data <- with(obs, list(
    N = nrow(obs),
    D = length(unique(police_department)),
    R = length(unique(race)),
    d = as.integer(police_department),
    r = as.integer(race),
    n = num_stops,
    s = num_searches,
    h = num_hits
  ))

str(stan_data)
```
#Question 2
```{stan output.var = "voting3_rng", eval = FALSE}
#stan function (though not syntactically correct- would appreciate your feedback on how to imrove)
functions {
  matrix voting3_rng(int S, matrix X, real [] intercept_scale,
                     real [] kids5_scale, real [] exper_scale, 
                     real [] motheduc_scale, real [] huswage_scale, 
                     real [] fatheduc_scale, real [] hours_scale,
                     real [] wage_scale) {
    int N = rows(X); int K = cols(X); matrix[S, N] out;
    for (s in 1:S) {
      vector[K] beta; vector[K] gamma; vector[N] z[2];
      real rho = uniform_rng(-1,1); real sigma = sqrt(1 - square(rho));
      int pos = 1;
  real binormal_cdf(real z1, real z2, real rho) {
    if (z1 != 0 || z2 != 0) {
      real denom = fabs(rho) < 1.0 ? sqrt((1 + rho) * (1 - rho)) : not_a_number();
      real a1 = (z2 / z1 - rho) / denom;
      real a2 = (z1 / z2 - rho) / denom;
      real product = z1 * z2;
      real delta = product < 0 || (product == 0 && (z1 + z2) < 0);
      return 0.5 * (Phi(z1) + Phi(z2) - delta) - owens_t(z1, a1) - owens_t(z2, a2);
    }
    return 0.25 + asin(rho) / (2 * pi());
    huswage_scale[];
    motheduc_scale[];
    fatheduc_scale[];
    kids5_scale[];
    hours_scale[];
    exper_scale[];
    wage_scale[];
}
  
data {
  int<lower=1> N; // number of observations
  int<lower=1> R; // number of suspect races
  int<lower=1> D;
  int pos = 1
}
  
parameters {
  // priors for utility work vs. utility not work (z1)
  beta[pos] = normal_rng(0, huswage_scale[]);
  pos += 1;
  beta[pos] = normal_rng(0, motheduc_scale[]);
  pos += 1;
  beta[pos] = normal_rng(0, fatheduc_scale[]);
  for (v in 1:2) {
    beta[pos] = normal_rng(0, kids5[1]);
    pos += 1;
    }
    // expected utility of work vs. not work given X
  z1 = normal_rng(0, 1) + X * beta;
    
    // priors for utility of being manager vs not being a manager (z2)
    
  gamma[pos] = normal_rng(0, hours_scale[]);
  pos += 1
  gamma[pos] = normal_rng(0, exper_scale[]);
  pos += 1
  gamma[pos] = normal_rng(0, wage_scale[]);
  pos += 1
    
    // expected utility of being manager vs not being a manager (z2)
  z2 = normal_rng(0, 1) + X * gamma;
}
  
model {
  for (n in 1:N) {
    real error_work = normal_rng(0, 1);
    int work = (z1[n] + error_work) > 0;
    if (work) {
      real error_prod = normal_rng(rho * error_work, sigma);
      out[n] = 1 + (z2[n] + error_prod) > 0;
    } else out[n] = 0;
  }
}
  return out;
}

```
#Continuation of Question 2
```{r, eval=FALSE}
      
data("Mroz87", package = "sampleSelection")
str(Mroz87)
expose_stan_functions("voting3_rng.stan")
X <- model.matrix( ~ huswage + motheduc + fatheduc + kids5 + hours + exper + wage,
                  data = Mroz87)
#inserted arbitrary priors for sclae variables - would appreciate your feedback on how best to determine these estimates 
PPD <- voting3_rng(10000, huswage_scale = 0.5, motheduc_scale = 0.4, kids5_scale = 0.3, hours_scale = 0.4, exper_scale = 0.2, wage_scale = 0.3)
prop.table(table(c(PPD)))

```
#Question 3
The paper "Mixing Methods: A Bayesian Approach" by Macartan Humphreys and Alan Jacob seems to be primarily focused on determining the optimal combination of quantitative causal inference and qualitative research. It was specifically focused on a subset of qualitative research called process tracing, which determines whether a hypothetical causal relationship exists by observing the "within-case evidence".  The two tests that were utilized were the smoking gun test which seeks sufficient conditions to determine the validity of a hypothesis whereas the hoop test has stricter parameters and seeks certain pieces of evidence that must be present in order for the hypothesis to be deemed true. The authors propose a combined approach, Bayesian integration of qualitative and quantitative (BIQQ) in which the causal processes are interpreted as types and the "within-case evidence" as clues. Thus, the inclusion of phi in the analysis, which is the probability of observing a clue for a given type.  

The woman towards the end of the video, mainly seemed to express difficulties interpreting the phis, specifically what the 0.9 was reflective of and how it was determined. Furthermore she questioned the validity of the process and highlighted the large dismissal of the so-called informative qualitative part of the research. She felt the phi was potentially too heavily weighted and highlighted the drawbacks of a researcher not having specific, well developed priors for the analysis. 

The researcher's response to these criticisms and some of the implications were on whether to give up on qualitative research altogether? "One response is to abandon the project of formally drawing inferences from clues. This is obviously not desirable because then that would mean that certain sources of information don't provide any information at all. And if we are constantly doing this informally, then it makes sense to try and do this in a more disciplined manner." (Humphreys & Jacobs 2015: 671). Essentially, to further refine the inclusion of priors once can ground the values in some systematic measure of the collective beliefs and although the formulation of these priors may be challenging, according to the researchers the level of difficult may be overstated. I found both the woman's concerns and the follow-up responses to be valid - however, it seemed as though the researchers may have downplayed the thorough process by which the phi was determined which is core for assessing the legitimacy of the approach.
